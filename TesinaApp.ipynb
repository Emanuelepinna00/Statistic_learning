{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "restricted-surname",
   "metadata": {},
   "source": [
    "# PROGETTO ESAME APPRENDIMENTO STATISTICO\n",
    "### Emanuele Pinna matr.296455\n",
    "## Analisi del dataset 'Wine quality'\n",
    "##### In questo progetto verrà analizzato il dataset 'winequality-red.csv', contenente campioni del vino rosso 'Vinho Verde' del nord del Portogallo.\n",
    "##### L'obbiettivo è quello di classificare i vari campioni nel dataset secondo la qualità del vino in base ai risultati delle prove chimico-fisiche testate nel campione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-forward",
   "metadata": {},
   "source": [
    "<img src='Wine.jpg'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educational-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import sklearn\n",
    "import FisherDA\n",
    "#import kfda\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from FisherDA import MultipleFisherDiscriminantAnalysis as FDA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import KernelPCA as KPCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#from kfda import Kfda as KFDA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ruled-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-shareware",
   "metadata": {},
   "source": [
    "##### Si vedano di seguito le prime 5 entrate del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alike-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-modem",
   "metadata": {},
   "source": [
    "<img src='test.png' style='width:1000px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-white",
   "metadata": {},
   "source": [
    "##### Questo dataset è composto da 1599 istanze e 11 features che rappresentano i dati chimico-fisici raccolti dai test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hazardous-screw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-silicon",
   "metadata": {},
   "source": [
    "##### Si controllino ora quali in quali colonne delle features si hanno valori mancanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marked-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-screw",
   "metadata": {},
   "source": [
    "##### Come si può notare dalla tabella sottostante non compaiono missing values, in quanto la riga corrispondente al count presenta solo il valore 1599 (numero delle istanze totali del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baking-library",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol  \n",
       "count  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983  \n",
       "std       0.154386     0.169507     1.065668  \n",
       "min       2.740000     0.330000     8.400000  \n",
       "25%       3.210000     0.550000     9.500000  \n",
       "50%       3.310000     0.620000    10.200000  \n",
       "75%       3.400000     0.730000    11.100000  \n",
       "max       4.010000     2.000000    14.900000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NON CI SONO MISSING VALUES\n",
    "data.iloc[:,:-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-breach",
   "metadata": {},
   "source": [
    "##### vedendo ora la distribuzione delle classi della qualità si nota che le classi sono molto disomogenee e addirittura mancano 5 classi di qualità (0,1,2,9,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tender-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "4     53\n",
      "8     18\n",
      "3     10\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_vc = data['quality'].value_counts()\n",
    "print(target_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "illegal-batman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>freq.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>681</td>\n",
       "      <td>0.425891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>638</td>\n",
       "      <td>0.398999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199</td>\n",
       "      <td>0.124453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>0.033146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>0.011257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.006254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         counts     freq.\n",
       "quality                  \n",
       "5           681  0.425891\n",
       "6           638  0.398999\n",
       "7           199  0.124453\n",
       "4            53  0.033146\n",
       "8            18  0.011257\n",
       "3            10  0.006254"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S,T = data.shape\n",
    "qual_freq = pd.concat([data['quality'].value_counts(), data['quality'].value_counts()/S], axis=1)\n",
    "qual_freq.columns = ['counts', 'freq.']\n",
    "qual_freq.index.name = 'quality'\n",
    "\n",
    "qual_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-crowd",
   "metadata": {},
   "source": [
    "##### Dalla tabella precedente si nota che il dataset ha una distribuzione molto poco equilibrata, difatti classi come la 5 e la 6 contengono più di 600 campioni mentre le altre vanno diminuendo sia verso 10 che verso l'1. Da questo se ne dedurrà uno scarso potere predittivo del supervised learning in quanto con classi sbilanciate si tende a valorizzare le classi più numerose risultando in una precisione più alta nelle stesse ma più bassa a livello generale. \n",
    "##### di seguito vi è il plot del numero di istanze per ogni qualità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attached-rough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bce8b9b7093404889273d0a3297d41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qual_counts = data['quality'].value_counts()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(len(qual_counts.values)), qual_counts.values)\n",
    "plt.xticks(ticks=np.arange(len(qual_counts.values)), \n",
    "           labels=qual_counts.index.to_list(),\n",
    "           rotation=15)\n",
    "plt.title('Quality DISTRIBUTION')\n",
    "plt.xlabel('classes')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-forest",
   "metadata": {},
   "source": [
    "##### e la matrice di correlazione tra le varie features, si può notare come le feature più correlate sono effettivamente le proprietà chimico fisiche dipendenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "monthly-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcef3845cb24eda9e6aaf777bd968b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "corrMatrix = data.iloc[:,:-1].corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-lawyer",
   "metadata": {},
   "source": [
    "##### Ora si crei un training set e un test set dal dataset iniziale con dimensioni del training set e del test set rispettivamente di 2/3 e 1/3 del datset inziale (dimensioni ottimali) in modo tale che la proporzione delle classi rimanga stratificata anche nel training e nel test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confirmed-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1],list(data['quality']),test_size = 0.33, random_state = 7, shuffle = True, stratify = list(data['quality']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-occurrence",
   "metadata": {},
   "source": [
    "##### Si mostrino ora le distribuzioni dei valori delle feature all'interno del training set (non si considera il test set per non avere dei 'leak' di informazioni dallo stesso compromettendo in seguito la generalità del modello)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coupled-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b064f607f9d44a7bd082630f61bee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONTROLLO RISCALAMENTO DATI\n",
    "plt.figure(figsize = [15,4])\n",
    "for col in X_train.columns[0:-1]:\n",
    "    plt.hist(X_train[col], bins=20, alpha = 0.5)\n",
    "    plt.xscale('linear')\n",
    "    plt.title('DISTRIBUTIONS')\n",
    "    plt.xlabel('values')\n",
    "    plt.ylabel('samples per bin')\n",
    "plt.legend(X_train.columns, loc ='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-decline",
   "metadata": {},
   "source": [
    "##### dal precedente grafico si può notare che i valori delle features non sono riscalati in quanto vi è una grande escursione tra i valori delle stesse.\n",
    "\n",
    "##### Per ovviare questo problema si riscalino tutti i valori delle feature attraverso la funzione di scikit-learn 'StandardScaler'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "protective-generic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>-0.232823</td>\n",
       "      <td>-1.975326</td>\n",
       "      <td>0.658409</td>\n",
       "      <td>-0.239127</td>\n",
       "      <td>-0.840129</td>\n",
       "      <td>2.143102</td>\n",
       "      <td>0.640948</td>\n",
       "      <td>-0.381398</td>\n",
       "      <td>0.125232</td>\n",
       "      <td>1.652047</td>\n",
       "      <td>0.816780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>-0.743794</td>\n",
       "      <td>0.907043</td>\n",
       "      <td>-1.397440</td>\n",
       "      <td>-0.453352</td>\n",
       "      <td>0.604637</td>\n",
       "      <td>-1.224008</td>\n",
       "      <td>-1.114653</td>\n",
       "      <td>-0.191438</td>\n",
       "      <td>0.257049</td>\n",
       "      <td>-0.343179</td>\n",
       "      <td>-0.676323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.334922</td>\n",
       "      <td>0.200580</td>\n",
       "      <td>0.350032</td>\n",
       "      <td>0.332138</td>\n",
       "      <td>0.137867</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>2.026949</td>\n",
       "      <td>1.623734</td>\n",
       "      <td>0.454774</td>\n",
       "      <td>-0.282718</td>\n",
       "      <td>-0.862961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.845893</td>\n",
       "      <td>-0.505883</td>\n",
       "      <td>1.018183</td>\n",
       "      <td>-0.024903</td>\n",
       "      <td>-0.528949</td>\n",
       "      <td>-0.646789</td>\n",
       "      <td>-0.560253</td>\n",
       "      <td>0.726701</td>\n",
       "      <td>-0.467943</td>\n",
       "      <td>-0.040872</td>\n",
       "      <td>0.350186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>-0.516696</td>\n",
       "      <td>0.624458</td>\n",
       "      <td>-0.523704</td>\n",
       "      <td>2.045934</td>\n",
       "      <td>1.804905</td>\n",
       "      <td>3.489947</td>\n",
       "      <td>1.595748</td>\n",
       "      <td>0.336228</td>\n",
       "      <td>-0.204310</td>\n",
       "      <td>-0.947793</td>\n",
       "      <td>-0.862961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1429      -0.232823         -1.975326     0.658409       -0.239127  -0.840129   \n",
       "1277      -0.743794          0.907043    -1.397440       -0.453352   0.604637   \n",
       "711        0.334922          0.200580     0.350032        0.332138   0.137867   \n",
       "406        0.845893         -0.505883     1.018183       -0.024903  -0.528949   \n",
       "1358      -0.516696          0.624458    -0.523704        2.045934   1.804905   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "1429             2.143102              0.640948 -0.381398  0.125232   \n",
       "1277            -1.224008             -1.114653 -0.191438  0.257049   \n",
       "711              0.026633              2.026949  1.623734  0.454774   \n",
       "406             -0.646789             -0.560253  0.726701 -0.467943   \n",
       "1358             3.489947              1.595748  0.336228 -0.204310   \n",
       "\n",
       "      sulphates   alcohol  \n",
       "1429   1.652047  0.816780  \n",
       "1277  -0.343179 -0.676323  \n",
       "711   -0.282718 -0.862961  \n",
       "406   -0.040872  0.350186  \n",
       "1358  -0.947793 -0.862961  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "scaler = SS().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pp_data = X_train.copy()\n",
    "\n",
    "for col,x in zip(X_train.columns, X_train_scaled.T):\n",
    "    pp_data[col] = x\n",
    "\n",
    "pp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-description",
   "metadata": {},
   "source": [
    "##### Si vedano ora le distrbuzioni dei valori riscalati delle features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heated-choice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb0f69c27e14a3bab5865c104b2226e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONTROLLO RISCALAMENTO DATI\n",
    "plt.figure(figsize = [15,4])\n",
    "for col in pp_data.columns:\n",
    "    plt.hist(pp_data[col], bins=20, alpha = 0.5)\n",
    "    plt.xscale('linear')\n",
    "    plt.title('DISTRIBUTIONS')\n",
    "    plt.xlabel('values')\n",
    "    plt.ylabel('samples per bin')\n",
    "plt.legend(pp_data.columns, loc ='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-basket",
   "metadata": {},
   "source": [
    "##### Di seguito invece si plotti, per ogni feature, la distribuzione dei campioni di ogni classe.\n",
    "##### Si può notare che molte feature portano più varianza tra le distribuzioni delle classi rispetto alle altre, questo si vedrà ancora meglio quando si farà la PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "agricultural-guide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6612af3c4c1e402ba083e3d1046415a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5c44e61b8c4d4c91fadaeee037c81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcea9beeb7734debbdaf723009ef4671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efadb407ea1464d8e377d9cb1ae901b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44759f1e76ef47c4a6d8c0bc1df0a0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7106906064642a3967789365d9c183e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b42f7a19b1451486559605753c43fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b42c9f097b4ac882669993397f8fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b164a6f1a371460488b264edb68837b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb49a8e31a3e44e293885738e32656c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bdb23fcbb6481ca0140c95333238d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SET DELLE QUALITA' DEI VINI\n",
    "qualities = set(y_train)\n",
    "\n",
    "# CALCOLO DI MEDIA E VARIANZA CAMPIONARIA\n",
    "means = []\n",
    "stds = []\n",
    "idx = range(len(qualities))\n",
    "\n",
    "datas = []\n",
    "\n",
    "for t,i in zip(qualities,idx):\n",
    "    datas.append(pp_data.iloc[np.where(np.array(y_train)==t)])\n",
    "    means.append([])\n",
    "    stds.append([])\n",
    "    for col in pp_data.columns:\n",
    "        means[i].append(np.mean(datas[i][col]))\n",
    "        stds[i].append(np.var(datas[i][col]))\n",
    "        \n",
    "means = np.array(means).T\n",
    "stds = np.array(stds).T\n",
    "\n",
    "\n",
    "# PLOT DEI RISULTATI OTTENUTI CON IL PREPROCESSING\n",
    "from scipy.stats import norm\n",
    "\n",
    "colors = ['b','g','r','c','m','y']\n",
    "for col,m,v in zip(pp_data.columns, means, stds):\n",
    "    plt.figure(figsize = [10,2])\n",
    "    plt.title(col)\n",
    "    for t,i,color in zip(qualities,idx, colors):\n",
    "        plt.hist(datas[i][col], density=True, color=color, alpha = 0.3)\n",
    "        x = np.linspace(m[i]-5*v[i],m[i]+5*v[i],100)\n",
    "        y = norm(m[i],v[i]).pdf(x)\n",
    "        plt.plot(x,y, color = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-minimum",
   "metadata": {},
   "source": [
    "# SUPERVISED LEARNING (Apprendimento supervisionato)\n",
    "L'apprendimento supervisionato, noto anche come apprendimento automatico supervisionato, è una sottocategoria di apprendimento automatico e intelligenza artificiale .\n",
    "È definito dall'uso di set di dati etichettati per addestrare algoritmi in grado di classificare i dati o prevedere i risultati in modo accurato.\n",
    "Quando i dati di input vengono inseriti nel modello, esso aggiusta i propri pesi fino a quando il modello non 'fitta' bene i dati, il che avviene come parte del processo di cross-validation.\n",
    "# Decision Tree Classifier (Albero decisionale)\n",
    "In generale i metodi basati sugli alberi sia dei buoni regressori che classificatori.\n",
    "L'idea principale è quella di dividere lo spazio delle feature $X$ in regioni più piccole per trovare una funzione di predizione per ogni regione.\n",
    "Poiché l'insieme di regole di divisione utilizzate per segmentare lo\n",
    "spazio predittore può essere riassunto in un albero, questi tipi di\n",
    "approcci sono noti come metodi _Decision-Tree_.\n",
    "#### Vantaggi e svantaggi\n",
    "<ul>\n",
    "  <li>I metodi basati sugli alberi sono semplici e di facile interpretazione</li>\n",
    "  <li>Non sono efficienti come i migliori approcci di supervised learning in termini di accuracy</li>\n",
    "  <li>Combinando un gran numero di alberi si può spesso ottenere un miglioramento nell'accuracy della predizione a scapito della difficoltà interpretativa</li>\n",
    "</ul>\n",
    "\n",
    "#### Processo di Tree-building\n",
    "<ol>\n",
    "  <li>Si divide lo spazio dei predittori (l'insieme di tutti i possibili valori per $X_1, X_2,\\dots, X_p$) in $J$ regioni distinte non sovrapposte</li>\n",
    "  <li>Per ogni osservazione che cade nella regione Rj, si fa la stessa predizione, che è semplicemente la media delle variabili response per le osservazioni del training set in $R_j$</li>\n",
    "</ol>\n",
    "\n",
    "In teoria, le regioni potrebbero avere una forma qualsiasi, ma per semplicità di implementazione e di interpretazione si preferisce dividere lo spazio dei predittori in 'scatole alto-dimensionali'.\n",
    "L'obbiettivo è quello di trovare le scatole $R1,\\dots,Rj$ tale da minimizzare il _RSS (Residual Sum of Squares)_ ovvero la _Loss_ calcolata come somma dei quadrati residua\n",
    "$$\\sum_{j=1}^J\\sum_{i\\in R_j}(y_i-\\hat{y}_{R_j})^2$$\n",
    "dove con $\\hat{y}_{R_j}$ si indica la media dei response per le osservazioni del training set nella j-esima scatola.\n",
    "L'algoritmo per la formazione dell'albero è il seguente:\n",
    "1. Si usi la divisione binaria ricorsiva per far crescere un grande albero sul file dati di addestramento, fermandosi solo quando ogni nodo terminale ha meno di un numero minimo di osservazioni.\n",
    "2. Applicare il cost complexity pruning al grande albero per ottenere una sequenza dei migliori sottoalberi, in funzione di $\\alpha$.\n",
    "3. Usare la K-fold cross-validation per scegliere $\\alpha$. Per ogni $k=1,\\dots,K$:\n",
    "    ripetere step 1 e 2 sulla $\\dfrac{K-1}{K}$ frazione del training data, escludendo il kesimo fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-statement",
   "metadata": {},
   "source": [
    "##### Si divida ora il training set a sua volta in training set e validation set, in modo tale da poter testare la performance del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "perfect-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X = pp_data\n",
    "y = y_train\n",
    "X_train_2, X_valid, y_train_2, y_valid = train_test_split(X,y,test_size=0.33,\n",
    "                                                   random_state=21,\n",
    "                                                   stratify=y,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-small",
   "metadata": {},
   "source": [
    "##### Si applichi ora un albero decisionale al training set precedentemente definito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "scientific-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.29      0.17      0.21        12\n",
      "           5       0.62      0.71      0.66       151\n",
      "           6       0.55      0.53      0.54       141\n",
      "           7       0.37      0.30      0.33        44\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.56       354\n",
      "   macro avg       0.31      0.28      0.29       354\n",
      "weighted avg       0.54      0.56      0.55       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST DECISION TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.tree import plot_tree\n",
    "dtc = DTC(criterion='gini',max_features='sqrt',\n",
    "          random_state=7,class_weight=None,max_depth=10)\n",
    "dtc.fit(X_train_2,y_train_2)\n",
    "pred_dtc = dtc.predict(X_valid)\n",
    "print(classification_report(y_valid, pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-aerospace",
   "metadata": {},
   "source": [
    "##### Come predetto in precedenza, le performance dell'albero decisionale sono scarse in quanto i campioni delle classi sono sbilanciati, risultando in una macro media di circa $0.29$\n",
    "##### Come accennato in precedenza, il vantaggio degli alberi decisionali è che essi hanno una struttura facilmente visualizzabile.\n",
    "##### Pertanto si veda qui di seguito la rappresentazione dell'albero risultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "built-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c1bd6387244e3a9e906a2691632930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plot_tree(dtc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-functionality",
   "metadata": {},
   "source": [
    "##### Si veda ora come subentra l'overfitting allìaumentare della profondità dell'albero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "persistent-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792a2e4c44174a6993d5aac54df92dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(1,14):\n",
    "    dtc = DTC(criterion='gini',max_features='sqrt',\n",
    "          random_state=7,class_weight=None,max_depth=i)\n",
    "    dtc.fit(X_train_2,y_train_2)\n",
    "    pred_dtc = dtc.predict(X_valid)\n",
    "    l.append(f1_score(y_valid, pred_dtc, average='macro'))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(13)+1,l)\n",
    "plt.xlabel('max depths')\n",
    "plt.ylabel('f1 scores')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-banner",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "Il Random Forest Classifier è un metodo di apprendimento supervisionato che costruisce un gran numero di alberi decisionali in degli insiemi campionati con reimmissione (Bootstrap Aggregating o Bagging) per poi passare ad un majority voting per scegliere a quale classe appartiene ogni punto del Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "narrative-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(max_depth=15, random_state=0, n_estimators=240)\n",
    "clf.fit(X_train_2, y_train_2)\n",
    "y_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "established-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31240681800477077"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_valid, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-looking",
   "metadata": {},
   "source": [
    "##### Si veda come varia l'overfitting con l'aumento della profondità massima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "white-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc92ed2ebe7147e9b70c7043d22ae88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(1,30):\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=7, n_estimators=70)\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    l.append(f1_score(y_valid, y_pred, average='macro'))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(29)+1,l)\n",
    "plt.xlabel('max depths')\n",
    "plt.ylabel('f1 scores')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-calibration",
   "metadata": {},
   "source": [
    "##### e come aumenta invece l'f1_score all'aumentare del numero di stimatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supposed-subsection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e02062732040359a2648f1c147120c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(1,30):\n",
    "    clf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=i*10)\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    l.append(f1_score(y_valid, y_pred, average='macro'))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(29)+1,l)\n",
    "plt.xlabel('number of estimators')\n",
    "plt.ylabel('f1 scores')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-peoples",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier\n",
    "Le Support Vector Machine sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione.\n",
    "Formalmente, una support vector machine costruisce un iperpiano o un insieme di iperpiani in uno spazio a più dimensioni o a infinite dimensioni.\n",
    "Intuitivamente una buona separazione si può ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) più vicino di ognuna delle classi; in generale maggiore è il margine fra questi punti, minore è l'errore di generalizzazione commesso dal classificatore.\n",
    "I vantaggi della SVM sono:\n",
    "* Buona generalizzazione\n",
    "* Lavora bene con gli insiemi ben separabili\n",
    "* Trova globalmente il miglior modello\n",
    "* L'algoritmo è efficiente\n",
    "* Si può utilizzare il kernel trick  \n",
    "Qualora le classi non siano separabili, si definisce un _soft margin_ (ovvero un margine entro il quale possono esserci punti che 'oltrepassano' il piano separatore nonostante appartengano alla stessa classe) che può esssere più o meno rigido a seconda di quanto vengono penalizzati i punti non separati.\n",
    "L'SVM è un problema di ottimizzazione risolvibile grazie ai moltiplicatori di Lagrange applicati al duale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "protective-scroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3071616195729671"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "clf2 = SVC(C=31)\n",
    "clf2.fit(X_train_2, y_train_2)\n",
    "y_pred = clf2.predict(X_valid)\n",
    "f1_score(y_valid, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "disturbed-northwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7732f84bb514ca7877a764ace58c65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(1,100):\n",
    "    clf2 = SVC(C=i)\n",
    "    clf2.fit(X_train_2, y_train_2)\n",
    "    y_pred = clf2.predict(X_valid)\n",
    "    l.append(f1_score(y_valid, y_pred, average='macro'))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(99)+1,l)\n",
    "plt.grid()\n",
    "plt.xlabel('Regularization Parameter')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-concrete",
   "metadata": {},
   "source": [
    "Il parametro C dell'SVM indica quanto si desidera evitare di classificare erroneamente ogni esempio di addestramento. Per valori elevati di C, l'ottimizzazione sceglierà un iperpiano con margine più piccolo se quell'iperpiano fa un lavoro migliore nel classificare correttamente tutti i punti di addestramento. Al contrario, un valore molto piccolo di C farà sì che l'ottimizzatore cerchi un iperpiano di separazione con margini maggiori, anche se quell'iperpiano classifica erroneamente più punti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-southwest",
   "metadata": {},
   "source": [
    "# UNSUPERVISED LEARNING\n",
    "L'Unsupervised Learning (o Apprendimento non supervisionato) si riferisce all'uso di algoritmi di intelligenza artificiale per identificare modelli in set di dati contenenti punti dati che non sono né classificati nè etichettati.\n",
    "In altre parole, l'apprendimento non supervisionato consente al sistema di identificare autonomamente i modelli all'interno del set di dati.\n",
    "Nell'apprendimento non supervisionato, un sistema di intelligenza artificiale raggruppa le informazioni non ordinate in base a somiglianze e differenze (tramite le features) anche se non vengono fornite classi.\n",
    "# Principal Component Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-minimum",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis\n",
    "La __Principal Component Analysis (PCA)__ è uno strumento molto utilizzato per la riduzione lineare della dimensionalità e per l'estrazione delle feature (caratteristiche).\n",
    "Lo scopo della PCA è quello di trovare un sottospazio lineare di dimensionalità fissata inferiore allo spazio delle feature originale, dove le nuove feature abbiano la massima varianza possibile.\n",
    "\n",
    "Si consideri un dataset $\\{x_i\\}$ dove $i=1,2,...,N$, ed ogni $x_i$ un vettore D-dimensionale.\n",
    "Ora si vuole proiettare i dati su un sottospazio M-dimensionale, con $M<D$.\n",
    "Assumendo la proiezione denotata come $y=Ax$, dove $A=[u_1^T,...,u_M^T]$ e $u_k^Tu_k=1$ per $k=1,2,...,M$, si cerca di massimizzare la varianza di $\\{y_i\\}$, che è la traccia della matrice di covarianza di $\\{y_i\\}$.\n",
    "Così, bisogna trovare $$A^*=\\arg\\max_A tr(S_y)$$ dove $$S_y=\\frac{1}{N}\\sum_{i=1}^N(y_i-\\bar{y})(y_i-\\bar{y})^T$$ e $$\\bar{y}=\\frac{1}{N}\\sum_{i=1}^Nx_i.$$\n",
    "Sia $S_x$ la matrice di covarianza di $\\{x_i\\}$. Dato che $tr(S_y)=tr(AS_xA^T)$, usando il Moltiplicatore Lagrangiano e prendendo le derivate, si ottiene $$S_xu_k=\\lambda_ku_k$$ che significa che $u_k$ è un autovettore di $S_x$. Ora $x_i$ può essere rappresentata come $$x_i=\\sum_{k=1}^D(x_i^Tu_k)u_k.$$\n",
    "$x_i$ può anche essere approssimato da $$\\tilde{x}_i=\\sum_{i=1}^M(x_i^Tu_k)u_k,$$\n",
    "dove $u_k$ è l'autovettore di $S_x$ corrispondente al k-esimo autovalore più grande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-timber",
   "metadata": {},
   "source": [
    "##### Si vedano di sequito qualsi sono le componenti principali che spiegano più varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "floppy-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pp_data.values\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "consolidated-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-27d3832d7bf7>:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize = [10,4])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b551d7b30f347c3a93a998b67fc8373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VOGLIO VEDERE QUALI SONO LE COMPONENTI PRINCIPALI CHE SPIEGANO PIU VARIANZA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "color = (0.2, 0.4, 0.6, 0.6)\n",
    "\n",
    "pca = PCA().fit(X,y)\n",
    "\n",
    "# scelta componenti principali\n",
    "plt.figure(figsize = [10,4])\n",
    "plt.plot(np.arange(1,12),pca.explained_variance_ratio_*100, 'ko')\n",
    "plt.plot(np.arange(1,12),pca.explained_variance_ratio_*100, 'k')\n",
    "for i,var in zip(range(1,12), pca.explained_variance_ratio_*100):\n",
    "    plt.annotate(round(var,2),[i,var])\n",
    "plt.bar(np.arange(1,12),height = pca.explained_variance_ratio_*100, color = color)\n",
    "plt.grid()\n",
    "plt.xlabel('principal components')\n",
    "plt.xticks(np.arange(1,12))\n",
    "plt.yticks(np.arange(0,50,5))\n",
    "plt.ylabel('explained variances')\n",
    "\n",
    "#plt.semilogy()\n",
    "plt.title('Wine PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-rapid",
   "metadata": {},
   "source": [
    "##### Si veda ora come aumenta la varianza spiegata con l'aggiunta delle componenti principali, si noti che il grafico prende la tipica forna a 'gomito' che ottimizza la scelta del numero di componenti principali da considerare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "modified-caribbean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c02b923944b43f9ad572a9a368b0b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# controllo sulla distribuzione cumulativa\n",
    "# scelta componenti principali\n",
    "\n",
    "plt.figure(figsize = [10,4])\n",
    "plt.plot(np.arange(1,12),pca.explained_variance_ratio_.cumsum()*100, 'ko')\n",
    "plt.plot(np.arange(1,12),pca.explained_variance_ratio_.cumsum()*100, 'k')\n",
    "for i,var in zip(range(1,12), pca.explained_variance_ratio_.cumsum()*100):\n",
    "    plt.annotate(round(var,2),[i,var])\n",
    "plt.bar(np.arange(1,12),height = pca.explained_variance_ratio_.cumsum()*100, color = color)\n",
    "plt.grid()\n",
    "plt.xlabel('principal components')\n",
    "plt.xticks(np.arange(1,12))\n",
    "plt.yticks(np.arange(0,110,10))\n",
    "plt.ylabel('explained variances')\n",
    "plt.title('Wine PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "facial-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pp_data.values\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hybrid-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cdf470498e4e799ec16f10ebaef3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_wine = PCA()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "Xscaled = scaler.transform(X)\n",
    "pca_wine.fit(Xscaled)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(100*np.insert(np.cumsum(pca_wine.explained_variance_ratio_), 0, 0))\n",
    "plt.title('Explained variance of Wine Dataset')\n",
    "plt.xticks(ticks=np.arange(1, pca_wine.n_features_ + 1), \n",
    "           labels=[f'PC{i}' for i in range(1, pca_wine.n_features_ + 1)])\n",
    "plt.yticks(ticks=np.arange(0, 101, 5))\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Percentage of cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-mention",
   "metadata": {},
   "source": [
    "##### Qui di seguito è rappresentato invece il grafico bidimensionale e tridimensionale delle classi rispetto alle prime 2 e 3 componenti principali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "palestinian-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3b5d0218ef41a99888c9b8d749582d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2395ec0130bf4d0d80b6ed2f844a26dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3D plot\n",
    "data_pca = pca.transform(pp_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "plt.title('PCA WINE QUALITIES 3D')\n",
    "for t,c,w in zip(qualities,['purple','c','gold','orange','crimson','mediumblue',\n",
    "                           'dimgrey'],['quality 3','quality 4','quality 5','quality 6',\n",
    "                                       'quality 7','quality 8']):\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.scatter(data_pca[np.where(np.array(y_train)==t)][:,0],\n",
    "               data_pca[np.where(np.array(y_train)==t)][:,1],\n",
    "               data_pca[np.where(np.array(y_train)==t)][:,2],\n",
    "               color = c, s = 30, label = w)\n",
    "ax.legend()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.show()\n",
    "\n",
    "#2D plot\n",
    "plt.figure(figsize = [8,4])\n",
    "for t,c,w in zip(qualities,['purple','c','gold','orange','crimson','mediumblue',\n",
    "                           'dimgrey'],['quality 3','quality 4','quality 5','quality 6',\n",
    "                                       'quality 7','quality 8']):\n",
    "    plt.scatter(data_pca[np.where(np.array(y_train)==t)][:,0],\n",
    "                data_pca[np.where(np.array(y_train)==t)][:,1], \n",
    "                s = 10, color = c, label = w)\n",
    "    plt.title('PCA WINE QUALITIES 2D')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "threaded-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero PC: 9\n",
      "% Varianza Tot. Spiegata: 0.9780910663818869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89acb06d369648c59491271d513502bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f235c9f525644013a13a22363f2ae044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_wine_m = PCA(0.95)\n",
    "pca_wine_m.fit(Xscaled)\n",
    "X_wine_m = pca_wine_m.transform(Xscaled)\n",
    "num_tosee = 1000\n",
    "print('Numero PC: {}'.format(pca_wine_m.n_components_))\n",
    "print('% Varianza Tot. Spiegata: {}'.format(pca_wine_m.explained_variance_ratio_.sum()))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_wine_m[:, 0], X_wine_m[:, 1], c=y, cmap='turbo')\n",
    "plt.title('WINE - SCORE GRAPH WITH 2 PCA')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig_beanscore = plt.figure(figsize=(8, 6))\n",
    "ax = fig_beanscore.add_subplot(111, projection='3d')\n",
    "ax.scatter(X_wine_m[:, 0], X_wine_m[:, 1], X_wine_m[:, 2], c=y, cmap='turbo')\n",
    "plt.title('WINE - SCORE GRAPH WITH 3 PCA')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-processor",
   "metadata": {},
   "source": [
    "Si riapplichi la SVM ai dati trasformati dalla PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "indirect-stability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09960159362549799"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_m = pca_wine_m.transform(X_test_scaled)\n",
    "clf2 = SVC(C=30)\n",
    "clf2.fit(X_wine_m, y_train)\n",
    "y_pred = clf2.predict(X_test_m)\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-traveler",
   "metadata": {},
   "source": [
    "# Loading Plot\n",
    "Il loading plot mostra la relazione tra le Principal Component e le variabili originali. Si utilizza per mostrare come le  features originali si relazionano ai PC, o viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-modification",
   "metadata": {},
   "source": [
    "##### Si mostrino di seguito i loading plot relativi alle componenti principali della PCA in 2 dimensioni e 3 dimensioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sought-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4236e72683f3471a8069a812b846ecab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016744e2239d412cba20f1f9f8fc1b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(pca_wine_m.n_features_):\n",
    "    plt.plot([0, pca_wine_m.components_[0, i]], [0, pca_wine_m.components_[1, i]], \n",
    "             label=pp_data.columns[i])\n",
    "plt.scatter(pca_wine_m.components_[0, :], pca_wine_m.components_[1, :], c='k')\n",
    "plt.legend()\n",
    "plt.title('WINE - LOADING GRAPH WITH 2 PC')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig_winescore = plt.figure()\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "for i in range(pca_wine_m.n_features_):\n",
    "    ax.plot([0, pca_wine_m.components_[0, i]], [0, pca_wine_m.components_[1, i]], \n",
    "            [0, pca_wine_m.components_[2, i]],\n",
    "             label=pp_data.columns[i])\n",
    "ax.scatter(pca_wine_m.components_[0, :], pca_wine_m.components_[1, :], pca_wine_m.components_[2, :], c='k')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), fontsize='xx-small')\n",
    "plt.title('WINE - LOADING GRAPH WITH 3 PC')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-ordinary",
   "metadata": {},
   "source": [
    "##### Un altro modo di vedere i Loading Graph è quello di plottarli in degli istogrammi, si vedano come le feature \"influenzano\" le prime 4 componenti principali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "charitable-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904214183c2f42549b4cfae247544962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbf0581786e4141aa96e83e57717df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6b61244d3f4582b57a304eff1a8926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc05f3526f5246e494617993670cc60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[0, :])\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=data.iloc[:,:-1].columns.to_list(),\n",
    "           rotation=30)\n",
    "plt.title('WINE - PC1')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[1, :])\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=pp_data.columns.to_list(),\n",
    "           rotation=30)\n",
    "plt.title('WINE - PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[2, :])\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=pp_data.columns.to_list(),\n",
    "           rotation=30)\n",
    "plt.title('WINE - PC3')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(pca_wine_m.n_features_), pca_wine_m.components_[3, :])\n",
    "plt.xticks(ticks=np.arange(pca_wine_m.n_features_), \n",
    "           labels=pp_data.columns.to_list(),\n",
    "           rotation=30)\n",
    "plt.title('WINE - PC4')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-citizen",
   "metadata": {},
   "source": [
    "# Fisher Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-child",
   "metadata": {},
   "source": [
    "#### Fisher Discriminant Analysis\n",
    "Si supponga di avere un dataset di istanze o di punti $\\{(x_i,y_i)\\}_{i=1}^n$ con $n$ la grandezza del campione e dimensionalità $x_i\\in \\mathbb{R}^d$ e $y_i\\in\\mathbb{R}^l$. Le $\\{x_i\\}_{i=1}^n$ sono i dati di input del modello e le $\\{y_i\\}_{i=1}^n$ sono le osservazioni (labels).\n",
    "Si definisce $\\mathbb{R}^{d\\times n} \\ni X:=[x_1,...,x_n]$ e $\\mathbb{R}^{l\\times n}\\ni Y:=[y_1,...,y_n]$. Di solito, i dati stanno su un sottospazio o una sotto-collezione.\n",
    "Qui, si considera il caso in cui le osservazioni $\\{y_i\\}_{i=1}^n$ vengano da un insieme discreto in modo tale che l'obiettivo sia la _classificazione_.\n",
    "Supponendo che il dataset consista di $c$ classi, $\\{x_i^{(1)}\\}_{i=1}^{n_1},...,\\{x_i^{(c)}\\}_{i=1}^{n_c}$ dove $n_j$ denota la cardinalità del campione della j-esima classe.\n",
    "Si vuole pertanto trovare un sottospazio (o sotto-collezione) che separi le classi il più possibile mentre i dati diventino il più sparsi possibile.\n",
    "La __Fisher Discriminant Analysis (FDA)__ persegue questo obiettivo cercando di massimizzare la distanza tra le classi proiettate e contemporaneamente minimizzare la varianza all'interno delle singole classi.\n",
    "La varianza delle classi viene rappresentata dalla cosiddetta _Between Scatter Matrix_ $S_B$\n",
    "\n",
    "__Sottospazio Multidimensionale__\n",
    "Nel caso in cui il sottospazio di Fisher è lo span di più direzioni di Fisher, $\\{u_j\\}_{i=1}^p$ dove $u_j \\in \\mathbb{R}^p$, il $d_B$ e $d_W$ sono definiti come:\n",
    "$$\\mathbb{R} \\ni d_B := tr(U^TS_BU),$$\n",
    "$$\\mathbb{R} \\ni d_W := tr(U^TS_WU),$$\n",
    "dove $\\mathbb{R}^{d\\times p}\\ni U=[u_1,...,u_p]$. In questo caso, massimizzare il _criterio di Fisher_ significa:\n",
    "$\\underset{U}{mazimize}\\;f(U):= \\frac{d_B(U)}{d_W(U)}=\\frac{tr(U^TS_BU)}{tr(U^TS_WU)}$.\n",
    "Il _criterio di Fisher_ $f(U)$ è un _quoziente generalizzato di Rayleigh-Ritz_.\n",
    "Pertanto l'ottimizzazione dell'equazione di sopra è equivalente a:\n",
    "$$\\underset{U}{mazimize}\\;tr(U^TS_BU)$$\n",
    "$$tale\\;che\\;U^TS_WU=I$$\n",
    "Il _Lagrangiano_ è:\n",
    "$$\\mathcal{L}=tr(U^TS_BU)-tr(\\Lambda^T(U^TS_WU-I))$$\n",
    "dove $\\Lambda\\in\\mathbb{R}^{d\\times d}$ è una matrice diagonale le cui entrate diagonali sono i _moltiplicatori di Lagrange_.\n",
    "Eguagliando le derivate di $\\mathcal{L}$ a zero si ottiene:\n",
    "$$\\mathcal{R}^{d\\times d}\\ni\\frac{\\partial \\mathcal{L}}{\\partial U}=2S_WU\\Lambda \\overset{set}{=}0\\implies 2S_BU=2S_WU\\Lambda\\implies S_BU=S_WU\\Lambda,$$\n",
    "che è un problema agli autovalori generalizzati $(S_B,S_W)$.\n",
    "Le colonne di $U$ sono gli autovettori ordinati dall'autovalore più grande al più piccolo (perchè in questo caso l'ottimizzazione è la massimizzazione) e le entrate diagonali di $\\Lambda$ sono gli autovalori corrispondenti. Le colonne di $U$ vengono anche chiamate le _direzioni di Fisher_ o gli _assi di Fisher_.\n",
    "Una possibile soluzione al problema agli autovalori generalizzati $(S_B,S_W)$ è:\n",
    "$$S_BU=S_WU\\Lambda\\implies S_W^{-1}S_BU=U\\Lambda\\implies U=eig((S_W+\\epsilon I)^{-1}S_B),$$\n",
    "Un altro modo per risolvere l'ottimizzazione sarebbe prendere le derivate dal _criterio di Fisher_:\n",
    "$$\\mathbb{R}^{d\\times p}\\ni\\frac{\\partial f(U)}{\\partial U}=\\frac{1}{(tr(U^TS_WU))^2}\\times [tr(U^TS_WU)(2S_BU)-tr(U^TS_BU)(2S_WU)]\\overset{set}{=}0\\overset{(a)}{\\implies}S_BU=\\frac{tr(U^TS_BU}{tr(U^TS_WU)}S_WU,$$\n",
    "dove $(a)$ vale in quanto $tr(U^TS_WU)$ è uno scalare.\n",
    "L'equazione sopra è un problema agli autovalori generalizzati $(S_B,S_W)$ con colonne di $U$ come autovettori e $(u_j^TS_Bu_j)/(u_j^TS_Wu_j)$ come il j-esimo autovalore (in quanto l'ottimizzazione è la massimizzazione).\n",
    "Di nuovo, un altro modo di trovare le direzioni FDA è di considerare un'altra versione del criterio di Fisher.\n",
    "Il _criterio di Fisher_ diventa\n",
    "$$f(U)=\\frac{tr(U^T(S_T-S_W)U)}{tr(U^TS_WU)}=\\frac{tr(U^TS_TU)}{tr(U^TS_WU)}-1.$$\n",
    "Il $-1$ è una costante e viene persa nell'ottimizzazione, pertanto:\n",
    "$$\\underset{U}{mazimize}\\;tr(U^TS_BU)$$\n",
    "$$tale\\;che\\;U^TS_WU=I$$\n",
    "le cui soluzioni sono similmente ottenute come:\n",
    "$$S_TU=S_WU\\Lambda,$$\n",
    "che è un problema agli autovalori generalizzati $(S_T,S_W)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "colored-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pp_data.values\n",
    "y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "egyptian-advocacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e1789ba89f4771b6b7ba7020022659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d290d2d23594d24822f984670047fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fda_wine2 = FDA(n_dimensions=2)\n",
    "fda_wine3 = FDA(n_dimensions=3)\n",
    "fda_wine2.fit(X,y)\n",
    "fda_wine3.fit(X,y)\n",
    "Z2m = fda_wine2.transform(X)\n",
    "Z3m = fda_wine3.transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Z2m[:, 0], Z2m[:, 1], c=y, cmap='turbo')\n",
    "plt.title('WINE - FDA GRAPH WITH 2 DIM')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig_winescore = plt.figure(figsize=(8, 6))\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "ax.scatter(Z3m[:, 0], Z3m[:, 1], Z3m[:, 2], c=y, cmap='turbo')\n",
    "plt.title('WINE - FDA GRAPH WITH 3 DIM')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-timothy",
   "metadata": {},
   "source": [
    "## SVM sui dati della FDA\n",
    "Si riapplichi la SVM ai dati trasformati dalla FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "military-heaven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09960159362549799"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_array = X_test.values\n",
    "y_test_array = np.array(y_test)\n",
    "X_test_fda = fda_wine3.transform(X_test_array)\n",
    "clf3 = SVC(C=30)\n",
    "clf3.fit(Z3m, y)\n",
    "y_pred = clf3.predict(X_test_fda)\n",
    "f1_score(y_test_array, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-kernel",
   "metadata": {},
   "source": [
    "##### Essendo le classi poco separabili nella FDA in 3 dimensioni, la precisione dell'SVM è molto bassa, risultando in un f1 score del 10% circa (ma, avendo solo 3 dimensioni è più performante che nello spazio iniziale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-coordinate",
   "metadata": {},
   "source": [
    "## Confronto plot FDA e PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adequate-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65630b61dfb4a369880632b5f8e5f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PCA')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot a confronto\n",
    "\n",
    "class_colors = [plt.cm.tab10.colors[c] for c in y[:num_tosee]]\n",
    "\n",
    "# Plot per proiezione in R^2\n",
    "fig2, axs2 = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs2[0].scatter(Z2m[:num_tosee, 0], Z2m[:num_tosee, 1], c=y[:num_tosee],alpha=1, cmap='turbo')\n",
    "axs2[0].set_title('FDA')\n",
    "axs2[1].scatter(X_wine_m[:num_tosee,0], X_wine_m[:num_tosee,1],c=y[:num_tosee], alpha=1, cmap='turbo')\n",
    "axs2[1].set_title('PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "weighted-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94b7e3f27ec48409825010bbcd92816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1e605783c148738cf3dbf3933713f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'PCA')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot a confronto\n",
    "\n",
    "# Plot per proiezione in R^3\n",
    "fig_Z3m = plt.figure(figsize=(5, 4))\n",
    "ax_Z3m = fig_Z3m.add_subplot(111, projection='3d')\n",
    "ax_Z3m.scatter(Z3m[:, 0], Z3m[:, 1], Z3m[:, 2], c=y, alpha=1, cmap='turbo')\n",
    "plt.title('FDA')\n",
    "\n",
    "fig_Z3p = plt.figure(figsize=(5, 4))\n",
    "ax_Z3p = fig_Z3p.add_subplot(111, projection='3d')\n",
    "ax_Z3p.scatter(X_wine_m[:, 0], X_wine_m[:, 1], X_wine_m[:, 2], c=y, alpha=1, cmap='turbo')\n",
    "plt.title('PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-combat",
   "metadata": {},
   "source": [
    "# KPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tender-cruise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90753fd353bd4677bf836009731e55ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754af6bc2c1843339442d0dad3f00e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_seed = 20210528\n",
    "kpca_wine = KPCA(kernel='poly', degree=2, coef0 = 4, gamma=0.4, random_state=random_seed, fit_inverse_transform=True)\n",
    "#expld_variance_global = np.insert(np.cumsum(kpca_iris.explained_variance_ratio_), 0, 0)\n",
    "Xkpca = kpca_wine.fit_transform(Xscaled)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Xkpca[:, 0], Xkpca[:, 1], c=y, cmap='turbo')\n",
    "plt.title('WINE - KPCA SCORE GRAPH WITH 2 PC')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig_winescoreK = plt.figure()\n",
    "ax = fig_winescoreK.add_subplot(111, projection='3d')\n",
    "ax.scatter(Xkpca[:, 0], Xkpca[:, 1], Xkpca[:, 2], c=y, cmap='turbo')\n",
    "plt.title('WINE - KPCA SCORE GRAPH WITH 3 PC')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "permanent-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c02b69b068d42559810c927eafb2654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "#plt.plot(np.insert(100*np.cumsum(kpca_bean.lambdas_)/np.sum(kpca_bean.lambdas_), 0, 0))\n",
    "plt.plot(np.insert(100*np.cumsum(kpca_wine.lambdas_)/np.sum(kpca_wine.lambdas_), 0, 0))\n",
    "plt.title('Explained variance of Wine Dataset')\n",
    "plt.xticks(ticks=np.arange(1, np.size(kpca_wine.lambdas_) + 1,10), \n",
    "           labels=[f'PC{i}' for i in range(1, np.size(kpca_wine.lambdas_) + 1,10)])\n",
    "plt.yticks(ticks=np.arange(0, 101, 5))\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Percentage of cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-architecture",
   "metadata": {},
   "source": [
    "##### Si faccia ora una gridsearch per vedere quali parametri di kernel portano la maggior varianza spiegata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "restricted-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_coef0</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.040577</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 4, 'degree': 2, 'gamma': 0.066666666...</td>\n",
       "      <td>-0.680863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732086</td>\n",
       "      <td>0.046975</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.834395e-26</td>\n",
       "      <td>-3.760876e-26</td>\n",
       "      <td>-3.351840e-26</td>\n",
       "      <td>-3.713153e-26</td>\n",
       "      <td>-3.488664e-26</td>\n",
       "      <td>-3.429786e-26</td>\n",
       "      <td>3.328512e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.047572</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 4, 'degree': 2, 'gamma': 0.083333333...</td>\n",
       "      <td>-0.647289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732607</td>\n",
       "      <td>0.072567</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.846493e-26</td>\n",
       "      <td>-3.856403e-26</td>\n",
       "      <td>-3.560013e-26</td>\n",
       "      <td>-3.709463e-26</td>\n",
       "      <td>-3.285009e-26</td>\n",
       "      <td>-3.451476e-26</td>\n",
       "      <td>3.566564e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 4, 'degree': 2, 'gamma': 0.111111111...</td>\n",
       "      <td>-0.738009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.764889</td>\n",
       "      <td>0.076214</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.976643e-26</td>\n",
       "      <td>-5.409481e-26</td>\n",
       "      <td>-3.588676e-26</td>\n",
       "      <td>-6.226883e-26</td>\n",
       "      <td>-3.900955e-26</td>\n",
       "      <td>-4.620527e-26</td>\n",
       "      <td>1.019795e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.043727</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 2, 'degree': 2, 'gamma': 0.066666666...</td>\n",
       "      <td>-0.819473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.806726</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.193613e-27</td>\n",
       "      <td>-2.335702e-27</td>\n",
       "      <td>-2.179091e-27</td>\n",
       "      <td>-2.482394e-27</td>\n",
       "      <td>-2.157599e-27</td>\n",
       "      <td>-2.269680e-27</td>\n",
       "      <td>1.234187e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'coef0': 0.5, 'degree': 2, 'gamma': 0.0833333...</td>\n",
       "      <td>-0.774775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.828968</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.977258e-27</td>\n",
       "      <td>-4.864801e-27</td>\n",
       "      <td>-4.150816e-27</td>\n",
       "      <td>-3.524008e-27</td>\n",
       "      <td>-3.510415e-27</td>\n",
       "      <td>-4.005460e-27</td>\n",
       "      <td>4.974447e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.100676</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.016379</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 1, 'degree': 3, 'gamma': 0.111111111...</td>\n",
       "      <td>-44.190187</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.391540</td>\n",
       "      <td>62.441752</td>\n",
       "      <td>236</td>\n",
       "      <td>-9.788427e-21</td>\n",
       "      <td>-1.082772e-19</td>\n",
       "      <td>-4.497367e-21</td>\n",
       "      <td>-2.584330e-20</td>\n",
       "      <td>-1.586112e-19</td>\n",
       "      <td>-6.140350e-20</td>\n",
       "      <td>6.134074e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.093682</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 2, 'degree': 3, 'gamma': 0.166666666...</td>\n",
       "      <td>-438.763801</td>\n",
       "      <td>...</td>\n",
       "      <td>-132.082253</td>\n",
       "      <td>174.692673</td>\n",
       "      <td>237</td>\n",
       "      <td>-1.416834e-15</td>\n",
       "      <td>-1.832937e-15</td>\n",
       "      <td>-1.561754e-16</td>\n",
       "      <td>-8.960832e-16</td>\n",
       "      <td>-1.555999e-15</td>\n",
       "      <td>-1.171606e-15</td>\n",
       "      <td>5.919907e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.085719</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 0.25, 'degree': 3, 'gamma': 0.166666...</td>\n",
       "      <td>-409.007979</td>\n",
       "      <td>...</td>\n",
       "      <td>-135.353786</td>\n",
       "      <td>169.361042</td>\n",
       "      <td>238</td>\n",
       "      <td>-2.558979e-16</td>\n",
       "      <td>-3.661827e-16</td>\n",
       "      <td>-7.292733e-18</td>\n",
       "      <td>-7.156463e-16</td>\n",
       "      <td>-3.072524e-17</td>\n",
       "      <td>-2.751490e-16</td>\n",
       "      <td>2.585287e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.081194</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 0.5, 'degree': 3, 'gamma': 0.1666666...</td>\n",
       "      <td>-1322.376678</td>\n",
       "      <td>...</td>\n",
       "      <td>-339.882431</td>\n",
       "      <td>510.960516</td>\n",
       "      <td>239</td>\n",
       "      <td>-4.859212e-16</td>\n",
       "      <td>-3.147575e-16</td>\n",
       "      <td>-8.553771e-17</td>\n",
       "      <td>-2.250383e-16</td>\n",
       "      <td>-3.152026e-16</td>\n",
       "      <td>-2.852915e-16</td>\n",
       "      <td>1.308031e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.015751</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'coef0': 1, 'degree': 3, 'gamma': 0.166666666...</td>\n",
       "      <td>-2621.413630</td>\n",
       "      <td>...</td>\n",
       "      <td>-585.878753</td>\n",
       "      <td>1024.038717</td>\n",
       "      <td>240</td>\n",
       "      <td>-1.078860e-15</td>\n",
       "      <td>-1.768238e-15</td>\n",
       "      <td>-5.745857e-17</td>\n",
       "      <td>-1.430752e-15</td>\n",
       "      <td>-1.367404e-15</td>\n",
       "      <td>-1.140543e-15</td>\n",
       "      <td>5.842200e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_coef0  \\\n",
       "220       0.040577      0.007657         0.006249        0.007653           4   \n",
       "216       0.047572      0.001252         0.005687        0.005239           4   \n",
       "212       0.050511      0.004117         0.004115        0.000208           4   \n",
       "172       0.043727      0.006225         0.009367        0.007648           2   \n",
       "73        0.040592      0.007665         0.006249        0.007653         0.5   \n",
       "..             ...           ...              ...             ...         ...   \n",
       "132       0.100676      0.003095         0.016379        0.000819           1   \n",
       "176       0.093682      0.009902         0.015675        0.000010           2   \n",
       "32        0.085719      0.006518         0.015718        0.000122        0.25   \n",
       "80        0.081194      0.006234         0.015687        0.000007         0.5   \n",
       "128       0.087500      0.007670         0.015751        0.000863           1   \n",
       "\n",
       "    param_degree param_gamma param_kernel  \\\n",
       "220            2    0.066667         poly   \n",
       "216            2    0.083333         poly   \n",
       "212            2    0.111111         poly   \n",
       "172            2    0.066667         poly   \n",
       "73             2    0.083333       linear   \n",
       "..           ...         ...          ...   \n",
       "132            3    0.111111         poly   \n",
       "176            3    0.166667         poly   \n",
       "32             3    0.166667         poly   \n",
       "80             3    0.166667         poly   \n",
       "128            3    0.166667         poly   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "220  {'coef0': 4, 'degree': 2, 'gamma': 0.066666666...          -0.680863   \n",
       "216  {'coef0': 4, 'degree': 2, 'gamma': 0.083333333...          -0.647289   \n",
       "212  {'coef0': 4, 'degree': 2, 'gamma': 0.111111111...          -0.738009   \n",
       "172  {'coef0': 2, 'degree': 2, 'gamma': 0.066666666...          -0.819473   \n",
       "73   {'coef0': 0.5, 'degree': 2, 'gamma': 0.0833333...          -0.774775   \n",
       "..                                                 ...                ...   \n",
       "132  {'coef0': 1, 'degree': 3, 'gamma': 0.111111111...         -44.190187   \n",
       "176  {'coef0': 2, 'degree': 3, 'gamma': 0.166666666...        -438.763801   \n",
       "32   {'coef0': 0.25, 'degree': 3, 'gamma': 0.166666...        -409.007979   \n",
       "80   {'coef0': 0.5, 'degree': 3, 'gamma': 0.1666666...       -1322.376678   \n",
       "128  {'coef0': 1, 'degree': 3, 'gamma': 0.166666666...       -2621.413630   \n",
       "\n",
       "     ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "220  ...        -0.732086        0.046975                1   \n",
       "216  ...        -0.732607        0.072567                2   \n",
       "212  ...        -0.764889        0.076214                3   \n",
       "172  ...        -0.806726        0.055629                4   \n",
       "73   ...        -0.828968        0.051075                5   \n",
       "..   ...              ...             ...              ...   \n",
       "132  ...       -42.391540       62.441752              236   \n",
       "176  ...      -132.082253      174.692673              237   \n",
       "32   ...      -135.353786      169.361042              238   \n",
       "80   ...      -339.882431      510.960516              239   \n",
       "128  ...      -585.878753     1024.038717              240   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "220       -2.834395e-26       -3.760876e-26       -3.351840e-26   \n",
       "216       -2.846493e-26       -3.856403e-26       -3.560013e-26   \n",
       "212       -3.976643e-26       -5.409481e-26       -3.588676e-26   \n",
       "172       -2.193613e-27       -2.335702e-27       -2.179091e-27   \n",
       "73        -3.977258e-27       -4.864801e-27       -4.150816e-27   \n",
       "..                  ...                 ...                 ...   \n",
       "132       -9.788427e-21       -1.082772e-19       -4.497367e-21   \n",
       "176       -1.416834e-15       -1.832937e-15       -1.561754e-16   \n",
       "32        -2.558979e-16       -3.661827e-16       -7.292733e-18   \n",
       "80        -4.859212e-16       -3.147575e-16       -8.553771e-17   \n",
       "128       -1.078860e-15       -1.768238e-15       -5.745857e-17   \n",
       "\n",
       "     split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "220       -3.713153e-26       -3.488664e-26     -3.429786e-26     3.328512e-27  \n",
       "216       -3.709463e-26       -3.285009e-26     -3.451476e-26     3.566564e-27  \n",
       "212       -6.226883e-26       -3.900955e-26     -4.620527e-26     1.019795e-26  \n",
       "172       -2.482394e-27       -2.157599e-27     -2.269680e-27     1.234187e-28  \n",
       "73        -3.524008e-27       -3.510415e-27     -4.005460e-27     4.974447e-28  \n",
       "..                  ...                 ...               ...              ...  \n",
       "132       -2.584330e-20       -1.586112e-19     -6.140350e-20     6.134074e-20  \n",
       "176       -8.960832e-16       -1.555999e-15     -1.171606e-15     5.919907e-16  \n",
       "32        -7.156463e-16       -3.072524e-17     -2.751490e-16     2.585287e-16  \n",
       "80        -2.250383e-16       -3.152026e-16     -2.852915e-16     1.308031e-16  \n",
       "128       -1.430752e-15       -1.367404e-15     -1.140543e-15     5.842200e-16  \n",
       "\n",
       "[240 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def my_scorer(estimator, X, y=None):\n",
    "    X_reduced = estimator.transform(X)\n",
    "    X_preimage = estimator.inverse_transform(X_reduced)\n",
    "    return -1 * mean_squared_error(X, X_preimage)\n",
    "\n",
    "n_features = data.shape[1]\n",
    "ker_list = ['poly','linear','rbf', 'cosine']\n",
    "gamma_list = [1/(i*n_features) for i in np.arange(0.5, 1.5, 0.25)]\n",
    "deg_list = [i for i in np.arange(1,4,1)]\n",
    "coef_list = [2**i for i in range(-2,3)]\n",
    "\n",
    "hparameters = {'kernel':ker_list, 'coef0':coef_list, 'gamma':gamma_list, 'degree':deg_list}\n",
    "kpca = KPCA(n_components=3, fit_inverse_transform=True)\n",
    "\n",
    "wine_kpca_GS = GridSearchCV(estimator=kpca, \n",
    "                      param_grid=hparameters, \n",
    "                      scoring=my_scorer,\n",
    "                      return_train_score=True)\n",
    "wine_kpca_GS.fit(Xscaled)\n",
    "df_results = pd.DataFrame(wine_kpca_GS.cv_results_)\n",
    "#indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 16]\n",
    "#df = df_results.iloc[:, indices]\n",
    "display(df_results.sort_values(['rank_test_score'], ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-kidney",
   "metadata": {},
   "source": [
    "##### Si plottino ora i punti nelle prime 3 componenti principali della KPCA con il miglior stimatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "helpful-glory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e658b1bb55444711a7be382782288a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722c36d440cf46ccba0e4d2575849307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine_kpca_GS.best_estimator_.fit(Xscaled)\n",
    "X_wine_K = wine_kpca_GS.transform(Xscaled)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_wine_K[:, 0], X_wine_K[:, 1], c=y, cmap='turbo')\n",
    "plt.title('WINE - KPCA SCORE GRAPH WITH 2 PCA')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig_winescore = plt.figure(figsize=(8, 6))\n",
    "ax = fig_winescore.add_subplot(111, projection='3d')\n",
    "ax.scatter(X_wine_K[:, 0], X_wine_K[:, 1], X_wine_K[:, 2], c=y, cmap='turbo')\n",
    "plt.title('WINE - KPCA SCORE GRAPH WITH 3 PCA')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-reply",
   "metadata": {},
   "source": [
    "# KFDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deadly-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfda\n",
    "from kfda import Kfda as KFDA\n",
    "kfda_2dim = KFDA(n_components=2, kernel='linear')\n",
    "kfda_2dim.fit(X,y)\n",
    "Z2k = kfda_2dim.transform(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-lincoln",
   "metadata": {},
   "source": [
    "##### Si plottino ora i punti in due dimensioni proiettati con la FDA e la KFDA con kernel lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "found-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b068eb2c1b504c41a051efe2649a859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'KFDA')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot per proiezione in R^2\n",
    "fig2, axs2 = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axs2[0].scatter(Z2m[:, 0], Z2m[:, 1], c=y, alpha=1,cmap= 'turbo')\n",
    "axs2[0].set_title('FDA')\n",
    "axs2[1].scatter(Z2k[:, 0], Z2k[:, 1], c=y, alpha=1,cmap= 'turbo')\n",
    "axs2[1].set_title('KFDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-window",
   "metadata": {},
   "source": [
    "##### Si faccia ora, come fatto in precedenza con i parametri della KPCA, una gridsearch per trovare il miglior stimatore per la KFDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "exotic-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112068</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "      <td>0.375828</td>\n",
       "      <td>0.446544</td>\n",
       "      <td>0.481415</td>\n",
       "      <td>0.505171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463808</td>\n",
       "      <td>0.049397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.981328</td>\n",
       "      <td>0.983665</td>\n",
       "      <td>0.995335</td>\n",
       "      <td>0.988336</td>\n",
       "      <td>0.984125</td>\n",
       "      <td>0.007738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091844</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>0.485947</td>\n",
       "      <td>0.454763</td>\n",
       "      <td>0.472353</td>\n",
       "      <td>0.378895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459221</td>\n",
       "      <td>0.043306</td>\n",
       "      <td>2</td>\n",
       "      <td>0.445485</td>\n",
       "      <td>0.479811</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>0.492551</td>\n",
       "      <td>0.473915</td>\n",
       "      <td>0.477166</td>\n",
       "      <td>0.017570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.092323</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'kernel': 'cosine'}</td>\n",
       "      <td>0.442820</td>\n",
       "      <td>0.431815</td>\n",
       "      <td>0.462236</td>\n",
       "      <td>0.341268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432248</td>\n",
       "      <td>0.048734</td>\n",
       "      <td>3</td>\n",
       "      <td>0.429174</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.428878</td>\n",
       "      <td>0.467513</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>0.439664</td>\n",
       "      <td>0.014327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116711</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'kernel': 'poly'}</td>\n",
       "      <td>0.376616</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.348038</td>\n",
       "      <td>0.389243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376041</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584126</td>\n",
       "      <td>0.540346</td>\n",
       "      <td>0.614427</td>\n",
       "      <td>0.564857</td>\n",
       "      <td>0.547331</td>\n",
       "      <td>0.570217</td>\n",
       "      <td>0.026806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.112068      0.008488         0.002925        0.002446          rbf   \n",
       "1       0.091844      0.007232         0.003928        0.005917       linear   \n",
       "2       0.092323      0.007850         0.000000        0.000000       cosine   \n",
       "3       0.116711      0.006814         0.009404        0.007679         poly   \n",
       "\n",
       "                 params  split0_test_score  split1_test_score  \\\n",
       "0     {'kernel': 'rbf'}           0.375828           0.446544   \n",
       "1  {'kernel': 'linear'}           0.485947           0.454763   \n",
       "2  {'kernel': 'cosine'}           0.442820           0.431815   \n",
       "3    {'kernel': 'poly'}           0.376616           0.351600   \n",
       "\n",
       "   split2_test_score  split3_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.481415           0.505171  ...         0.463808        0.049397   \n",
       "1           0.472353           0.378895  ...         0.459221        0.043306   \n",
       "2           0.462236           0.341268  ...         0.432248        0.048734   \n",
       "3           0.348038           0.389243  ...         0.376041        0.024704   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.971963            0.981328   \n",
       "1                2            0.445485            0.479811   \n",
       "2                3            0.429174            0.435200   \n",
       "3                4            0.584126            0.540346   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.983665            0.995335            0.988336   \n",
       "1            0.494067            0.492551            0.473915   \n",
       "2            0.428878            0.467513            0.437554   \n",
       "3            0.614427            0.564857            0.547331   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.984125         0.007738  \n",
       "1          0.477166         0.017570  \n",
       "2          0.439664         0.014327  \n",
       "3          0.570217         0.026806  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = data.shape[1]\n",
    "#ker_list = ['rbf', 'linear', 'poly', 'sigmoid', 'cosine']\n",
    "ker_list = ['rbf', 'linear', 'cosine','poly']\n",
    "gamma_list = [1/(i*n_features) for i in np.arange(0.5, 1.5, 0.25)]\n",
    "deg_list = [i for i in np.arange(1,5,1)]\n",
    "coef_list = [2**i for i in range(-2,3)]\n",
    "\n",
    "hparameters = {'kernel':ker_list}\n",
    "kfda3 = KFDA(n_components=3, robustness_offset=3e-8)\n",
    "\n",
    "kfda_wine_GS3 = GridSearchCV(estimator=kfda3, \n",
    "                      param_grid=hparameters, \n",
    "                      scoring='f1_weighted',\n",
    "                      return_train_score=True);\n",
    "kfda_wine_GS3.fit(X,y);\n",
    "df_results = pd.DataFrame(kfda_wine_GS3.cv_results_);\n",
    "#indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 16]\n",
    "#df = df_results.iloc[:, indices]\n",
    "display(df_results.sort_values(['rank_test_score'], ascending=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "modified-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20387f7ac9f942de8d59fcd71798b438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'KFDA')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfda_wine_GS3.best_estimator_.fit(X, y)\n",
    "X_wine_Kfda3 = kfda_wine_GS3.transform(X)\n",
    "\n",
    "fig_Z3K = plt.figure(figsize=(10, 8))\n",
    "ax_Z3K = fig_Z3K.add_subplot(111, projection='3d')\n",
    "ax_Z3K.scatter(X_wine_Kfda3[:, 0], X_wine_Kfda3[:, 1], X_wine_Kfda3[:, 2], c=y, alpha=0.5, cmap='turbo')\n",
    "plt.title('KFDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-carry",
   "metadata": {},
   "source": [
    "Si applichi ora una SVM ai dati modificati dalla kfda, si può notare che, dato che la varianza spiegata è aumentata di gran lunga rispetto ai dati normali, la precisione della SVM è salita fino al $43%$ usando solo 3 dimensioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "close-talent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42613636363636365"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "X_test_array = X_test.values\n",
    "y_test_array = np.array(y_test)\n",
    "X_test_kfda = kfda_wine_GS3.transform(X_test_array)\n",
    "clf3 = SVC(C=0.2)\n",
    "clf3.fit(X_wine_Kfda3, y)\n",
    "y_pred = clf3.predict(X_test_kfda)\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "associate-hanging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b4c4b527604b7a8a8ab013f023d2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb4cdfa801248c49a52ff3303cd8015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'FDA')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_Z3K = plt.figure(figsize=(5, 4))\n",
    "ax_Z3K = fig_Z3K.add_subplot(111, projection='3d')\n",
    "ax_Z3K.scatter(X_wine_Kfda3[:, 0], X_wine_Kfda3[:, 1], X_wine_Kfda3[:, 2], c=y, alpha=1, cmap='turbo')\n",
    "plt.title('KFDA')\n",
    "\n",
    "fig_Z3m = plt.figure(figsize=(5, 4))\n",
    "ax_Z3m = fig_Z3m.add_subplot(111, projection='3d')\n",
    "ax_Z3m.scatter(Z3m[:, 0], Z3m[:, 1], Z3m[:, 2], c=y, alpha=1, cmap='turbo')\n",
    "plt.title('FDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-addition",
   "metadata": {},
   "source": [
    "# Appendice sugli RKHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-newman",
   "metadata": {},
   "source": [
    "## 1. REPRODUCING KERNEL HILBERT SPACES\n",
    "### 1.1 _Definizione di funzionale di valutazione di Dirac_\n",
    "Sia $ \\mathbb{H} $ lo spazio $ \\mathbb{L}_2 (X) $ di funzioni da $X$ in $\\mathbb{R}$ per qualche insieme non vuoto $X$. Si definisce il __funzionale di valutazione di Dirac in $x$__ il funzionale $\\delta_x$ tale che $$ \\delta_x : \\mathbb{H} \\to \\mathbb{R}\\quad \\text{tale che}\\quad\\delta_x (f) = f(x) $$\n",
    "$\\delta_x$ è continuo se esiste una costante $M>0$, $M \\in \\mathbb{R}$ tale che $$ \\lvert\\lvert{\\delta_x (f)\\rvert\\rvert}_{\\mathbb{L}_2} = \\lvert{f(x)\\rvert} \\leq M \\lvert\\lvert{f\\rvert\\rvert}_{\\mathbb{L}_2} \\quad \\forall f \\in \\mathbb{H}, \\quad \\forall x \\in \\mathbb{R}^n $$\n",
    "\n",
    "### 1.2 _Definizione di RKHS_\n",
    "Un __RKHS__ (Reproducing Kernel Hilbert Space) è uno spazio di Hilbert in cui ogni funzionale di valutazione di Dirac è continuo.\n",
    "\n",
    "### 1.3 _Teorema di rappresentazione di Riesz_\n",
    "Sia $\\mathbb{H}$ uno spazio di Hilbert. Allora per ogni funzionale lineare e continuo $\\Phi$ su $\\mathbb{H}$, esiste ed è unico un elemento $u$ di $\\mathbb{H}$ tale che $$ \\Phi (f) = \\langle f, u \\rangle_{\\mathbb{H}} $$\n",
    "\n",
    "Nel caso dei funzionali di valutazione di Dirac, se siamo in un RKHS allora per ogni $\\delta_x$ esiste ed è unico $k_x \\in \\mathbb{H}$ tale che $$ \\delta_x (f) = f(x) = \\langle f, k_x \\rangle_{\\mathbb{H}} $$\n",
    "$k_x$ viene detto __representer in $x$__.\n",
    "\n",
    "### 1.4 _Definizione di Reproducing Kernel_\n",
    "Sia $\\mathbb{H}$ uno spazio di Hilbert di funzioni da $X$ in $\\mathbb{R}$ con $X$ insieme non vuoto. Una funzione $\\mathcal{K} : X \\times X \\to \\mathbb{R}$ si dice __Reproducing Kernel__ di $\\mathbb{H}$ se soddisfa:\n",
    "* $\\forall x \\in X \\quad k_x = \\mathcal{K}(\\cdot,x) \\in \\mathbb{H}$, $k_x$ si dice __representer in $x$__\n",
    "* $\\mathcal{K}(x,x) < \\infty \\quad \\forall x \\in X$\n",
    "* $\\forall x \\in X, \\forall f \\in \\mathbb{H} \\quad \\langle f, \\mathcal{K}(\\cdot,x) \\rangle = f(x)$ (__Reproducing Property__)\n",
    "\n",
    "Osserviamo che $k_x \\in \\mathbb{H}$ è una funzione da $X$ in $\\mathbb{R}$ tale che $k_x (y) = \\mathcal{K}(x,y)$\n",
    "In particolare, per ogni $x,y \\in X$ $$ \\langle k_x, k_y \\rangle_{\\mathbb{H}} = \\langle \\mathcal{K}(\\cdot,x), \\mathcal{K}(\\cdot,y) \\rangle_{\\mathbb{H}} = \\mathcal{K}(x,y) = \\mathcal{K}(y,x) $$ dove $k_x, k_y$ sono rispettivamente i representer di $\\delta_x, \\delta_y$. Segue chiaramente che $\\mathcal{K}$ è simmetrico e definito positivo, perche discende dal prodotto scalare su $\\mathbb{H}$.\n",
    "\n",
    "Chiaramente se $k_x \\in \\mathbb{H} \\;\\; \\forall x \\in X$, allora $\\textbf{span}\\{ k_x : x \\in X \\} \\subseteq \\mathbb{H}$, quindi se $f = \\sum_{j=1}^N \\alpha_j \\mathcal{K}(\\cdot,x_j)$ con $x_j \\in X$, allora $$ \\vert\\vert f \\vert\\vert_{\\mathbb{H}}^2 = \\sum_{j=1}^N \\sum_{i=1}^N \\alpha_j \\alpha_i \\langle \\mathcal{K}(\\cdot, x_j),\\mathcal{K}(\\cdot, x_i) \\rangle_{\\mathbb{H}} = \\sum_{j=1}^N\\sum_{i=1}^N \\alpha_j \\alpha_i \\mathcal{K}(x_j, x_i) $$\n",
    "\n",
    "### 1.5 _Teorema di unicità_\n",
    "Se esiste, il reproducing kernel $\\mathcal{K}$ per uno spazio di Hilbert $\\mathbb{H}$ è unico.\n",
    "##### _Dimostrazione_\n",
    "Assumiamo che $\\mathbb{H}$ abbia due Reproducing Kernel $\\mathcal{K}_1$ e $\\mathcal{K}_2$. Allora $$ \\langle f, \\mathcal{K}_1 (\\cdot, x) - \\mathcal{K}_2 (\\cdot, x) \\rangle = f(x) - f(x) = 0 \\quad \\forall f \\in \\mathbb{H},\\; \\forall x \\in X $$\n",
    "In particolare, se prendiamo $f = \\mathcal{K}_1 (\\cdot, x) - \\mathcal{K}_2 (\\cdot, x)$ otteniamo $$ \\vert\\vert \\mathcal{K}_1 (\\cdot, x) - \\mathcal{K}_2 (\\cdot, x) \\vert\\vert_{\\mathbb{H}}^2 = 0 \\;\\; \\forall x \\in X \\implies \\mathcal{K}_1 = \\mathcal{K}_2 $$\n",
    "\n",
    "### 1.6 _Equivalenza tra Reproducing Kernel e $\\delta_x$ limitato_\n",
    "Sia $\\mathbb{H}$ uno spazio di Hilbert di funzioni $f : X \\to\\mathbb{R}$. Allora gli operatori di valutazione $\\delta_x$ sono funzionali limitati e continui $\\iff$ $\\mathbb{H}$ ha un Reproducing Kernel $\\mathcal{K}$\n",
    "##### _dimostrazione_\n",
    "$( \\Longleftarrow )$ Poiché $\\mathbb{H}$ è uno spazio di Hilbert con Reproducing Kernel $\\mathcal{K}$, allora $$ | \\delta_x f | = | f(x) | = | \\langle f, \\mathcal{K} (\\cdot, x) \\rangle_{\\mathbb{H}} | \\leq || \\mathcal{K}(\\cdot, x ) ||_{\\mathbb{H}} || f ||_{\\mathbb{H}} = \\langle \\mathcal{K}(\\cdot, x), \\mathcal{K}(\\cdot, x) \\rangle_{\\mathbb{H}}^{\\frac{1}{2}} || f ||_{\\mathbb{H}} = \\mathcal{K}(x,x)^{\\frac{1}{2}} || f ||_{\\mathbb{H}} $$\n",
    "$ \\implies $ $\\delta_x : \\mathbb{H} \\to \\mathbb{R}$ è un operatore lineare e limitato.\n",
    "\n",
    "$ ( \\Longrightarrow ) $ Supponiamo che $\\delta_x : \\mathbb{H} \\to \\mathbb{R}$ sia un funzionale lineare e limitato.\n",
    "Allora per il teorema di rappresentazione di Riesz $\\implies$ $\\exists f_{\\delta_x} \\in \\mathbb{H}$ tale che $\\delta_x f = \\langle f, f_{\\delta_x} \\rangle_{\\mathbb{H}}\\;\\; \\forall f \\in \\mathbb{H} $. Definiamo $\\mathcal{K} (x', x) = f_{\\delta_x} (x') \\quad \\forall x, x' \\in X$. Allora $$ \\mathcal{K} (\\cdot, x) = f_{\\delta_x} \\;\\; \\text{e}\\;\\; \\langle f, \\mathcal{K} (\\cdot, x) \\rangle_{\\mathbb{H}} = \\delta_x f = f(x) $$\n",
    "$\\implies$ $\\mathcal{K}$ è un Reproducing Kernel per $\\mathbb{H}$\n",
    "\n",
    "### 1.7 _Definizione di Kernel_\n",
    "Una funzione $\\mathcal{K} : X \\times X \\to \\mathbb{R} $ si dice __Kernel__ su un insieme non vuoto $X$ se esiste uno spazio di Hilbert $\\mathbb{H}$ (non necessariamente RKHS) e una mappa $\\Phi : X \\to \\mathbb{H}$, tale che $$ \\mathcal{K}(x,y) = \\langle \\Phi(x), \\Phi(y) \\rangle_{\\mathbb{H}} $$\n",
    "$\\Phi$ è chiamata __Feature Map__, e $\\mathbb{H}$ è chiamato __Feature Space__\n",
    "\n",
    "Si dimostra che ogni Reproducing Kernel è anche un Kernel. \n",
    "Basta prendere come $\\Phi$ la funzione che manda $ x \\mapsto \\mathcal{K}(\\cdot,x) = k_x$, con $k_x \\in \\mathbb{H}$ e quindi $\\mathcal{K}(x,y) = \\langle \\mathcal{K},\\mathcal{K}(\\cdot, y) \\rangle_{\\mathbb{H}}$. Allora il RKHS $\\mathbb{H}$ è il Feature Space.\n",
    "__N.B.__ Non vale il viceversa, in quanto verrebbe meno l'unicità.\n",
    "\n",
    "Un Kernel $\\mathcal{K}$ può essere visto come una matrice di infinite dimensioni, ma nonostante questo esistono due diverse definizioni di Kernel definito positivo, equivalenti nel caso di Kernel continui.\n",
    "\n",
    "#### 1.7.1 _Kernel definito positivo_\n",
    "Un Kernel simmetrico $\\mathcal{K} : X \\times X \\to \\mathbb{R}$ si dice __(semi-)definito positivo__ su $X$ se la sua matrice di kernel associata $(\\mathcal{K})_{i,j} = \\mathcal{K}(x_i, x_j)_{i,j=1}^N$ è (semi-)definita positiva $\\forall N \\in \\mathbb{N}$ e per ogni insieme di punti distinti $\\{ x_1, \\ldots, x_N \\} \\subset X$.\n",
    "\n",
    "#### 1.7.2 _Kernel integralmente definito positivo_\n",
    "Un Kernel simmetrico $\\mathcal{K} : X \\times X \\to \\mathbb{R}$ si dice __semi-definito positivo in $\\mathbb{L}_2$__ se per ogni funzione $f \\in \\mathbb{L}_2$ si ha che $$ \\int_X \\int_X f(x) \\mathcal{K}(x,x') f(x') dx dx' \\geq 0 $$\n",
    "ed si dice __definito positivo in $\\mathbb{L}_2$__ se l'integrale è uguale a $0$ $\\iff$ $f \\equiv 0$ quasi ovunque.\n",
    "\n",
    "#### 1.8 _Teorema_\n",
    "Ogni Kernel è una funzione semi-definita positiva.\n",
    "\n",
    "##### _Dimostrazione_\n",
    "Siano $\\{ x_1, \\ldots, x_N \\} \\subset X$ distinti e $c \\in \\mathbb{R}^N$. Abbiamo che \n",
    "$$ \\sum_{i=1}^N \\sum_{j=1}^N c_i c_j \\mathcal{K} (x_i, x_j) =\\sum_{i=1}^N \\sum_{j=1}^N c_i c_j \\langle \\phi (x_i), \\phi (x_j) \\rangle_{\\mathbb{H}} =\\bigg\\langle \\sum_{i=1}^N c_i \\phi (x_i), \\sum_{j=1}^N c_j \\phi (x_j) \\bigg\\rangle_{\\mathbb{H}} = \\bigg|\\bigg| \\sum_{i=1}^N c_i \\phi (x_i) \\bigg|\\bigg|_{\\mathbb{H}}^2 \\geq 0$$\n",
    "Reproducing Kernel $\\implies$ Kernel $\\implies$ funzione semi-definita positiva\n",
    "\n",
    "Un primo modo per costruire un RKHS a partire da un Kernel e dato dal seguente risultato\n",
    "### 1.9 _Teorema di Moore-Aronszajn_\n",
    "Sia $\\mathcal{K} : X \\times X \\to \\mathbb{R}$ un kernel definito positivo. Allora esiste ed è unico (a meno di isomorfismi) un RKHS $\\mathbb{H}_{\\mathcal{K}} \\in \\mathbb{R}^X$ con Reproducing Kernel $\\mathcal{K}$.\n",
    "\n",
    "##### _Dimostrazione Teorema_\n",
    "Per ipotesi $\\mathcal{K}$ è un Kernel definito positivo. Definiamo $\\mathbb{H}_0 = \\textbf{span} \\{ k_x : x \\in X \\}$, per cui ogni elemento di $\\mathbb{H}_0$ può essere scritto come $\\sum_i \\alpha_i k_{x_i} = \\sum_i \\alpha_i \\mathcal{K}(\\cdot, x_i) $, e ci definiamo una forma bilineare $$ \\langle f_1, f_2 \\rangle_{\\mathcal{K}} = \\bigg\\langle \\sum_{i=1}^N \\alpha_i \\mathcal{K}(\\cdot, x_i), \\sum_{j=1}^N \\beta_j \\mathcal{K}(\\cdot, y_j) \\bigg\\rangle_{\\mathcal{K}} =\\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\beta_j \\mathcal{K} (x_i, y_j) $$\n",
    "##### 1.9.1 _Lemma_\n",
    "Se $\\mathcal{K} : X \\times X \\to \\mathbb{R}$ è un Kernel simmetrico definito positivo $\\implies$ $\\langle \\cdot, \\cdot \\rangle_{\\mathcal{K}}$ definisce un prodotto interno su $\\mathbb{H}_0$. Inoltre $\\mathbb{H}_0$ è uno spazio pre-hilbertiano con Reproducing Kernel $\\mathcal{K}$.\n",
    "##### _Dimostrazione Lemma_\n",
    "Ovviamente $\\langle \\cdot, \\cdot \\rangle_{\\mathcal{K}}$ è bilineare e simmetrico. Inoltre, se consideriamo una qualsiasi funzione $f = \\sum_{j=1}^N \\alpha_j \\mathcal{K}(\\cdot, x_j) \\not= 0$ in $\\mathbb{H}_0$, troviamo che $$ \\langle f, f \\rangle_{\\mathcal{K}} = \\sum_{j = 1}^N \\sum_{k = 1}^N \\alpha_j \\alpha_k \\mathcal{K} (x_j, x_k) > 0 $$\n",
    "perché per ipotesi $\\mathcal{K}$ è definito positivo. Infine otteniamo che $$ \\langle f, \\mathcal{K}(\\cdot, y) \\rangle_{\\mathcal{K}} = \\sum_{j=1}^N \\alpha_j \\mathcal{K} (x_j, y) = f(y) $$\n",
    "$\\implies$ $\\mathbb{H}_0$ è uno spazio pre-hilbertiano con Reproducing Kernel $\\mathcal{K}$.\n",
    "\n",
    "Notiamo però che $\\mathbb{H}_0$ non è necessariamente completo, per cui cerchiamo di farne il completamento. Definiamo quindi $\\mathbb{H}_{\\mathcal{K}}$ come lo spazio di funzioni $f \\in \\mathbb{R}^X$ per esiste una sequenza $\\{ f_n \\}$ di Cauchy in $\\mathbb{H}_0$. Fissiamo $x \\in X$ e consideriamo $$ | f_n (x) - f_m (x) | = | \\langle \\mathcal{K}(x,\\cdot), f_n - f_m \\rangle | \\leq || \\mathcal{K} (x,\\cdot) ||_{\\mathbb{H}_0} || f_n - f_m ||_{\\mathbb{H}_0} = \\langle \\mathcal{K}(x,\\cdot), \\mathcal{K}(x,\\cdot) \\rangle^{\\frac{1}{2}}_{\\mathbb{H}_0} || f_n - f_m ||_{\\mathbb{H}_0} = \\mathcal{K}(x,x)^{\\frac{1}{2}} || f_n - f_m ||_{\\mathbb{H}_0} $$ \n",
    "Per definizione sappiamo che $\\mathcal{K}(x,x) < \\infty \\;\\; \\forall x \\in X$, da cui segue che $\\{ f_n (x) \\}$ è una successione limitata di Cauchy in $\\mathbb{R}$, che è completo $\\implies$ esiste $f(x) = \\lim f_n (x)$. Allora aggiungiamo a $\\mathbb{H}_0$ tutte le funzioni così definite per ottenere $\\mathbb{H}_{\\mathcal{K}}$, per cui infine $\\forall x \\in X$ abbiamo che \n",
    "$$ f(x) = \\lim_{n \\to \\infty} f_n (x) = \\lim_{n \\to \\infty} \\langle f_n, \\mathcal{K}(\\cdot,x) \\rangle_{\\mathbb{H}_0} = \\langle f, \\mathcal{K}(\\cdot,x) \\rangle_{\\mathbb{H}_{\\mathcal{K}}} $$ per cui $\\mathcal{K}$ e' il Reproducing Kernel di $\\mathbb{H}_{\\mathcal{K}}$.\n",
    "\n",
    "Un'altra costruzione di RKHS a partire da un Kernel viene data in termini di autofunzioni associate all'operatore con nucleo integrale definito da $$ T_{\\mathcal{K}}(q)(x) = \\int_X \\mathcal{K}(x,y) q(y) dy \\quad q \\in \\mathbb{L}_2 (X), \\; x \\in X $$\n",
    "Affinche questo operatore sia ben definito, e necessario che la norma in $\\mathbb{L}_2 (X)$ sia finita $$ \\int \\int \\mathcal{K}^2 (x,x') dx dx' < \\infty \\implies \\mathcal{K}(\\cdot,x) \\in \\mathbb{L}_2 (X) $$\n",
    "Questa proprieta si dice __traccia finita__.\n",
    "### 1.10 _Teorema di Mercer_\n",
    "Sia $\\mathcal{K}$ un Kernel definito positivo, continuo e con traccia finita. Sia $T_{\\mathcal{K}}$ l'operatore con nucleo integrale definito sopra, che sappiamo essere ben definito. Allora esiste una sequenza infinita di autofunzioni $\\{ \\phi_i \\}_{i =0}^{\\infty} $ e di autovalori $\\{ \\lambda_i \\}_{i=0}^{\\infty}$ di $T_{\\mathcal{K}}$, con $\\lambda_1 \\geq \\lambda_2 \\geq \\ldots$ tale che $\\mathcal{K}$ puo essere scritto come $$ \\mathcal{K} (x,x') = \\sum_{i = 0}^{\\infty} \\lambda_i \\phi_i (x) \\phi_i (x') $$\n",
    "\n",
    "Questo risultato permette di costruire un RKHS $\\mathbb{H}_{\\mathcal{K}}$ in questo modo: $$ \\mathbb{H}_{\\mathcal{K}} := \\bigg\\{ f : f = \\sum_{i = 0}^{\\infty} c_i \\phi_i \\bigg\\} $$\n",
    "Chiaramente $f \\in \\mathbb{L}_2$, per cui i coefficienti saranno dati da $$ f_i = \\langle f, \\phi_i \\rangle_{\\mathbb{L}_2} = \\int f(x) \\phi_i (x) dx $$\n",
    "E' un risultato base dell'analisi di Fourier che tale rappresentazione esiste ed e' unica.\n",
    "\n",
    "Dato cio', possiamo ora definire il prodotto interno su $\\mathbb {H}_{\\mathcal{K}}$:\n",
    "$$\\langle f,g \\rangle_{\\mathbb{H}_{\\mathcal{K}}} = \\sum_{i=0}^{\\infty} \\frac{f_i g_i}{\\lambda_i}$$\n",
    "dove abbiamo usato la $\\mathbb{H}_{\\mathcal{K}}$-ortogonalita' $\\langle \\phi_j, \\phi_k \\rangle_{\\mathbb{H}_{\\mathcal{K}}} = \\cfrac{\\delta_{j,k}}{\\sqrt{\\lambda_j}\\sqrt{\\lambda_k}}$ delle autofunzioni.\n",
    "\n",
    "__Nota:__ $\\mathcal{K}$ e' il reproducing kernel di $\\mathbb{H}_{\\mathcal{K}}$ dato che l'espansione in autofunzioni di $\\mathcal{K}$, data dal _Teorema di Mercer_, e l'ortogonalita' delle autofunzioni implicano che $$\\langle f,\\mathcal{K}(\\cdot,x)\\rangle_{\\mathbb{H}_{\\mathcal{K}}} = \\bigg\\langle\\sum_{j=0}^\\infty c_j\\phi_j, \\sum_{j=0}^\\infty \\lambda_i \\phi_i \\phi_i(x)\\bigg\\rangle_{\\mathbb{H}_{\\mathcal{K}}} = \\sum_{i=0}^\\infty \\cfrac{c_i\\lambda_i\\phi_i(x)}{\\lambda_i} = \\sum_{i=0}^\\infty c_i\\phi_i(x) = f(x)$$\n",
    "\n",
    "### 1.11 _Kernel trick_\n",
    "Dato un kernel $\\mathcal{K}$ esiste una feature map associata $\\Phi : X\\to\\mathbb{H}$ tale che\n",
    "$$\\mathcal{K}(x,x') = \\langle \\Phi(x),\\Phi(x')\\rangle_{\\mathbb{H}}$$\n",
    "per esempio dato un kernel $\\mathcal{K}$ esiste una funzione $\\Phi$ tale che la valutazione del kernel nei punti $x$ e $x'$ e' equivalente a prendere il profotto scalare tra $\\Phi(x)$ $\\Phi(x')$ in alcuni (forse sconosciuti) spazi di Hilbert.\n",
    "\n",
    "Questo ci da' la possibilita' di utilizzare il _kernel trick_, nel quale trasformiamo gli input in $\\mathbb{H}$ usando $\\Phi$ e quindi prendiamo il prodotto scalare come prima.\n",
    "\n",
    "Abbiamo visto come costruire un _RKHS_ $\\mathbb{H}$ partendo da un kernel definito positivo e che $\\mathbb{H}_{\\mathcal{K}}$ e' unico a meno di isomorfismi.\n",
    "\n",
    "Questo significa che $\\Phi$ non e' unico in modo assoluto, ma lo e' preso $\\mathbb{H}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
